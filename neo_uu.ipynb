{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork_uu import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = Unet(device).to(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "for x in vgg.parameters():\n",
    "    x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lr1 = 0.001\n",
    "lr2 = 0.0002\n",
    "\n",
    "lr_fast = 0.0003\n",
    "lr_slow = 0.0002\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 1\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loss_li = []\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 50) == 0:\n",
    "        #     pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "    neo_pic = model(input)\n",
    "    pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    pil.save(f\"mid.jpg\")\n",
    "\n",
    "\n",
    "    # torch.save(model,'unet.pth')\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    opt_fast = optim.Adam(model.parameters(), lr=lr2)\n",
    "    opt_slow = optim.Adam(model.parameters(), lr=lr_fast)\n",
    "    # opt_loss = optim.Adam(cliploss.parameters(), lr=lr_slow)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        opt_slow.zero_grad()\n",
    "        opt_fast.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "#         patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.get_image_prior_losses(neo_pic)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "\n",
    "        patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        patch_loss_fast *= patch_lambda\n",
    "        patch_loss_slow *= patch_lambda\n",
    "\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_fast.backward(retain_graph=True)\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_slow.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = True\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        opt_fast.step()\n",
    "        opt_slow.step()\n",
    "\n",
    "        loss_li.append(loss.item())\n",
    "\n",
    "        print(\"iter:\", i + 1, \"fast_loss:\", patch_loss_fast.item(), \"slow_loss:\", patch_loss_slow.item())\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic2/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pil = Image.open(f\"./source_pic/face2.jpeg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "source = \"photo\"\n",
    "# target = \"Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Impression Sunrise by Monet\"\n",
    "# target = \"cyberpunk 2077\"\n",
    "# target = \"oil painting of flowers\"\n",
    "# target = \"neon light\"\n",
    "# target = \"fire\"\n",
    "target = \"Chinese Ink and wash painting\"\n",
    "# target = \"Expressionism\"\n",
    "# target = \"pencil painting\"\n",
    "\n",
    "\n",
    "path = \"result0.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.11828456819057465\n",
      "iter: 2 loss: 0.058912329375743866\n",
      "iter: 3 loss: 0.031664784997701645\n",
      "iter: 4 loss: 0.01695530116558075\n",
      "iter: 5 loss: 0.0093210618942976\n",
      "iter: 6 loss: 0.005719942972064018\n",
      "iter: 7 loss: 0.004166668280959129\n",
      "iter: 8 loss: 0.00339171732775867\n",
      "iter: 9 loss: 0.0029642153531312943\n",
      "iter: 10 loss: 0.002749711275100708\n",
      "iter: 11 loss: 0.0026394424494355917\n",
      "iter: 12 loss: 0.0025724824517965317\n",
      "iter: 13 loss: 0.002519907196983695\n",
      "iter: 14 loss: 0.002456829883158207\n",
      "iter: 15 loss: 0.002396353054791689\n",
      "iter: 16 loss: 0.00234105228446424\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n",
    "\n",
    "\n",
    "\n",
    "# 186.4968602657318\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(file = \"neo0.txt\", mode = \"w\") as file:\n",
    "    for i in loss_li:\n",
    "        file.write(str(i)+\" \")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "#\n",
    "# x = [i for i in range(100)]\n",
    "# plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}