{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork_uu import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = Unet(device).to(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "# vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "# for x in vgg.parameters():\n",
    "#     x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lr1 = 0.001\n",
    "lr2 = 0.0003\n",
    "\n",
    "# lr_fast = 0.0003\n",
    "# lr_slow = 0.0004\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 150\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "file_uu = open(\"neo0.txt\", \"r\")\n",
    "loss_li = file_uu.readline()\n",
    "loss_li = [float(x) for x in loss_li.split()]\n",
    "if not loss_li:\n",
    "    loss_li = [0]*100\n",
    "\n",
    "cur_times = int(file_uu.readline())\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 50) == 0:\n",
    "        #     pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "\n",
    "    neo_pic = model(input)\n",
    "    pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    pil.save(f\"mid.jpg\")\n",
    "\n",
    "\n",
    "    # torch.save(model,'unet.pth')\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_fast = optim.Adam(model.parameters(), lr=lr_fast)\n",
    "    # opt_slow = optim.Adam(model.parameters(), lr=lr_slow)\n",
    "    # opt_loss = optim.Adam(cliploss.parameters(), lr=lr_slow)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # opt_slow.zero_grad()\n",
    "        # opt_fast.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "        # patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.forward_prior(pic, source, neo_pic, target)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "\n",
    "        patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        patch_loss_fast *= patch_lambda\n",
    "        patch_loss_slow *= patch_lambda\n",
    "\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_slow.backward(retain_graph=True)\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = False\n",
    "        # for x in model.deconv3.parameters():\n",
    "        #     x.requires_grad = False\n",
    "        patch_loss_fast.backward(retain_graph=True)\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = True\n",
    "        # for x in model.deconv3.parameters():\n",
    "        #     x.requires_grad = True\n",
    "\n",
    "        loss.backward()\n",
    "        # (loss+patch_loss_fast+patch_loss_slow).backward()\n",
    "\n",
    "\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_li[i]+=(loss+patch_loss_fast+patch_loss_slow).item()\n",
    "\n",
    "            print(\"iter:\", i + 1, \"fast_loss:\", patch_loss_fast.item(), \"slow_loss:\", patch_loss_slow.item())\n",
    "            print(\"iter:\", i + 1, \"loss:\", (loss+patch_loss_fast+patch_loss_slow).item())\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic2/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_9932\\1470568555.py:4: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n"
     ]
    }
   ],
   "source": [
    "pil = Image.open(f\"./source_pic/pig.jpg\")\n",
    "# pil = Image.open(f\"resulto.jpg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# source = \"cat\"\n",
    "# source = \"photo\"\n",
    "# source = \"CG picture\"\n",
    "source = \"happy\"\n",
    "# source = \"woman\"\n",
    "\n",
    "target = \"angry\"\n",
    "# target = \"pop art\"\n",
    "# target = \"man\"\n",
    "# target = \"Watercolor Art with Thick Brush\"\n",
    "# target = \"Pixar\"\n",
    "# target = \"watercolor painting\"\n",
    "# target = \"Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Monet\"\n",
    "# target = \"cyberpunk 2077\"\n",
    "# target = \"oil painting of flowers\"\n",
    "# target = \"man with dark black skin and black hair\"\n",
    "# target = \"The great wave off kanagawa by Hokusai\"\n",
    "# target = \"fire\"\n",
    "# target = \"Chinese Brush Painting of mountains in black and white\"\n",
    "# target = \"Expressionism\"\n",
    "# target = \"gold boat\"\n",
    "# target = \"sketch in black and white\"\n",
    "# target = \"pop art of night city\"\n",
    "# target = \"wall paintings\"\n",
    "# target = \"Japanese anime\"\n",
    "\n",
    "\n",
    "path = \"result/resulto.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.19787053763866425\n",
      "iter: 2 loss: 0.13852518796920776\n",
      "iter: 3 loss: 0.10971485078334808\n",
      "iter: 4 loss: 0.08937327563762665\n",
      "iter: 5 loss: 0.07612970471382141\n",
      "iter: 6 loss: 0.06488293409347534\n",
      "iter: 7 loss: 0.05548728257417679\n",
      "iter: 8 loss: 0.04718528315424919\n",
      "iter: 9 loss: 0.040033768862485886\n",
      "iter: 10 loss: 0.03399849683046341\n",
      "iter: 11 loss: 0.028876714408397675\n",
      "iter: 12 loss: 0.024596411734819412\n",
      "iter: 13 loss: 0.021006613969802856\n",
      "iter: 14 loss: 0.018014000728726387\n",
      "iter: 15 loss: 0.01556549221277237\n",
      "iter: 16 loss: 0.013519173488020897\n",
      "iter: 17 loss: 0.011788630858063698\n",
      "iter: 18 loss: 0.010315490886569023\n",
      "iter: 19 loss: 0.009058334864675999\n",
      "iter: 20 loss: 0.00798090547323227\n",
      "iter: 21 loss: 0.007065407931804657\n",
      "iter: 22 loss: 0.006294587627053261\n",
      "iter: 23 loss: 0.005638325121253729\n",
      "iter: 24 loss: 0.005067556165158749\n",
      "iter: 25 loss: 0.004564389586448669\n",
      "iter: 26 loss: 0.00412577111274004\n",
      "iter: 27 loss: 0.0037535629235208035\n",
      "iter: 28 loss: 0.00344017893075943\n",
      "iter: 29 loss: 0.0031779406126588583\n",
      "iter: 30 loss: 0.002955570351332426\n",
      "iter: 31 loss: 0.0027618210297077894\n",
      "iter: 32 loss: 0.002587258815765381\n",
      "iter: 33 loss: 0.0024236845783889294\n",
      "iter: 34 loss: 0.002265593037009239\n",
      "iter: 35 loss: 0.0021149106323719025\n",
      "iter: 36 loss: 0.0019744166638702154\n",
      "iter: 37 loss: 0.0018454843666404486\n",
      "iter: 38 loss: 0.0017294407589361072\n",
      "iter: 39 loss: 0.0016269851475954056\n",
      "iter: 40 loss: 0.0015367190353572369\n",
      "iter: 41 loss: 0.0014557072427123785\n",
      "iter: 42 loss: 0.0013798604486510158\n",
      "iter: 43 loss: 0.0013084544334560633\n",
      "iter: 44 loss: 0.0012439520796760917\n",
      "iter: 45 loss: 0.001186382258310914\n",
      "iter: 46 loss: 0.0011345621896907687\n",
      "iter: 47 loss: 0.0010875070001929998\n",
      "iter: 48 loss: 0.001044485718011856\n",
      "iter: 49 loss: 0.0010049818083643913\n",
      "iter: 50 loss: 0.0009688392165116966\n",
      "iter: 51 loss: 0.0009358943207189441\n",
      "iter: 52 loss: 0.0009061179589480162\n",
      "iter: 53 loss: 0.0008794233435764909\n",
      "iter: 54 loss: 0.0008552687941119075\n",
      "iter: 55 loss: 0.0008330831187777221\n",
      "iter: 56 loss: 0.0008124784799292684\n",
      "iter: 57 loss: 0.00079327606363222\n",
      "iter: 58 loss: 0.0007754418766126037\n",
      "iter: 59 loss: 0.0007588923908770084\n",
      "iter: 60 loss: 0.0007432910497300327\n",
      "iter: 61 loss: 0.0007282942533493042\n",
      "iter: 62 loss: 0.0007136376807466149\n",
      "iter: 63 loss: 0.0006992588751018047\n",
      "iter: 64 loss: 0.0006852803053334355\n",
      "iter: 65 loss: 0.0006719101220369339\n",
      "iter: 66 loss: 0.0006593500729650259\n",
      "iter: 67 loss: 0.0006476353155449033\n",
      "iter: 68 loss: 0.0006365453591570258\n",
      "iter: 69 loss: 0.0006258178036659956\n",
      "iter: 70 loss: 0.0006153122521936893\n",
      "iter: 71 loss: 0.0006050383672118187\n",
      "iter: 72 loss: 0.0005950948689132929\n",
      "iter: 73 loss: 0.0005855601048097014\n",
      "iter: 74 loss: 0.0005764371599070728\n",
      "iter: 75 loss: 0.0005676182336173952\n",
      "iter: 76 loss: 0.0005589918000623584\n",
      "iter: 77 loss: 0.000550521188415587\n",
      "iter: 78 loss: 0.0005422390531748533\n",
      "iter: 79 loss: 0.0005342201911844313\n",
      "iter: 80 loss: 0.0005264804931357503\n",
      "iter: 81 loss: 0.0005189884104765952\n",
      "iter: 82 loss: 0.000511672580614686\n",
      "iter: 83 loss: 0.0005044911522418261\n",
      "iter: 84 loss: 0.0004974490730091929\n",
      "iter: 85 loss: 0.0004905880196020007\n",
      "iter: 86 loss: 0.00048394734039902687\n",
      "iter: 87 loss: 0.0004775004927068949\n",
      "iter: 88 loss: 0.0004711960209533572\n",
      "iter: 89 loss: 0.00046498520532622933\n",
      "iter: 90 loss: 0.0004588811134453863\n",
      "iter: 91 loss: 0.00045293974108062685\n",
      "iter: 92 loss: 0.00044719487777911127\n",
      "iter: 93 loss: 0.00044162984704598784\n",
      "iter: 94 loss: 0.00043619712232612073\n",
      "iter: 95 loss: 0.0004308663192205131\n",
      "iter: 96 loss: 0.00042564523755572736\n",
      "iter: 97 loss: 0.00042054872028529644\n",
      "iter: 98 loss: 0.00041558570228517056\n",
      "iter: 99 loss: 0.0004107349959667772\n",
      "iter: 100 loss: 0.00040596755570732057\n",
      "iter: 1 fast_loss: 4104.6982421875 slow_loss: 5095.046875\n",
      "iter: 1 loss: 10004.16796875\n",
      "iter: 2 fast_loss: 4397.75830078125 slow_loss: 4517.02880859375\n",
      "iter: 2 loss: 9703.208984375\n",
      "iter: 3 fast_loss: 4647.216796875 slow_loss: 4020.44677734375\n",
      "iter: 3 loss: 9442.8330078125\n",
      "iter: 4 fast_loss: 4256.24072265625 slow_loss: 4251.9833984375\n",
      "iter: 4 loss: 9268.6416015625\n",
      "iter: 5 fast_loss: 3664.3525390625 slow_loss: 4752.4111328125\n",
      "iter: 5 loss: 9163.431640625\n",
      "iter: 6 fast_loss: 3443.939208984375 slow_loss: 4762.84765625\n",
      "iter: 6 loss: 8941.205078125\n",
      "iter: 7 fast_loss: 3055.915771484375 slow_loss: 4870.6513671875\n",
      "iter: 7 loss: 8650.986328125\n",
      "iter: 8 fast_loss: 3304.82470703125 slow_loss: 4555.6181640625\n",
      "iter: 8 loss: 8572.6123046875\n",
      "iter: 9 fast_loss: 2935.40966796875 slow_loss: 4679.83251953125\n",
      "iter: 9 loss: 8323.4111328125\n",
      "iter: 10 fast_loss: 2915.42822265625 slow_loss: 4603.34033203125\n",
      "iter: 10 loss: 8218.4375\n",
      "iter: 11 fast_loss: 2831.657470703125 slow_loss: 4531.2421875\n",
      "iter: 11 loss: 8047.31689453125\n",
      "iter: 12 fast_loss: 2987.73193359375 slow_loss: 4217.51416015625\n",
      "iter: 12 loss: 7875.1630859375\n",
      "iter: 13 fast_loss: 2204.9560546875 slow_loss: 4916.24462890625\n",
      "iter: 13 loss: 7779.869140625\n",
      "iter: 14 fast_loss: 2558.647216796875 slow_loss: 4397.07177734375\n",
      "iter: 14 loss: 7606.3896484375\n",
      "iter: 15 fast_loss: 3057.4951171875 slow_loss: 3788.909912109375\n",
      "iter: 15 loss: 7487.32763671875\n",
      "iter: 16 fast_loss: 2935.68408203125 slow_loss: 3776.275634765625\n",
      "iter: 16 loss: 7339.1328125\n",
      "iter: 17 fast_loss: 2788.1240234375 slow_loss: 3844.322265625\n",
      "iter: 17 loss: 7250.11962890625\n",
      "iter: 18 fast_loss: 2577.04931640625 slow_loss: 4003.692626953125\n",
      "iter: 18 loss: 7193.1650390625\n",
      "iter: 19 fast_loss: 2452.49169921875 slow_loss: 4072.97509765625\n",
      "iter: 19 loss: 7133.89013671875\n",
      "iter: 20 fast_loss: 2200.90478515625 slow_loss: 4227.40185546875\n",
      "iter: 20 loss: 7036.23046875\n",
      "iter: 21 fast_loss: 2389.3203125 slow_loss: 3978.69873046875\n",
      "iter: 21 loss: 6979.94384765625\n",
      "iter: 22 fast_loss: 2604.4462890625 slow_loss: 3770.64501953125\n",
      "iter: 22 loss: 6986.017578125\n",
      "iter: 23 fast_loss: 2129.5625 slow_loss: 4110.4658203125\n",
      "iter: 23 loss: 6847.4560546875\n",
      "iter: 24 fast_loss: 2566.886962890625 slow_loss: 3685.638427734375\n",
      "iter: 24 loss: 6856.2041015625\n",
      "iter: 25 fast_loss: 3018.425048828125 slow_loss: 3146.896484375\n",
      "iter: 25 loss: 6769.5009765625\n",
      "iter: 26 fast_loss: 2660.33935546875 slow_loss: 3355.0185546875\n",
      "iter: 26 loss: 6615.03857421875\n",
      "iter: 27 fast_loss: 2355.33154296875 slow_loss: 3569.526611328125\n",
      "iter: 27 loss: 6520.7900390625\n",
      "iter: 28 fast_loss: 2752.41845703125 slow_loss: 3209.381103515625\n",
      "iter: 28 loss: 6555.9814453125\n",
      "iter: 29 fast_loss: 2835.91455078125 slow_loss: 3106.2470703125\n",
      "iter: 29 loss: 6534.59375\n",
      "iter: 30 fast_loss: 2322.441162109375 slow_loss: 3480.949462890625\n",
      "iter: 30 loss: 6396.3232421875\n",
      "iter: 31 fast_loss: 2859.60400390625 slow_loss: 2922.70654296875\n",
      "iter: 31 loss: 6378.9931640625\n",
      "iter: 32 fast_loss: 2316.87939453125 slow_loss: 3311.0732421875\n",
      "iter: 32 loss: 6224.63525390625\n",
      "iter: 33 fast_loss: 2720.97021484375 slow_loss: 2986.358642578125\n",
      "iter: 33 loss: 6302.26171875\n",
      "iter: 34 fast_loss: 2456.54296875 slow_loss: 3311.4853515625\n",
      "iter: 34 loss: 6361.2119140625\n",
      "iter: 35 fast_loss: 2948.318359375 slow_loss: 2683.20458984375\n",
      "iter: 35 loss: 6219.70751953125\n",
      "iter: 36 fast_loss: 2480.16357421875 slow_loss: 3108.58154296875\n",
      "iter: 36 loss: 6177.931640625\n",
      "iter: 37 fast_loss: 2557.75439453125 slow_loss: 2991.9892578125\n",
      "iter: 37 loss: 6138.431640625\n",
      "iter: 38 fast_loss: 2838.31787109375 slow_loss: 2654.571533203125\n",
      "iter: 38 loss: 6082.328125\n",
      "iter: 39 fast_loss: 2858.8486328125 slow_loss: 2630.88232421875\n",
      "iter: 39 loss: 6074.919921875\n",
      "iter: 40 fast_loss: 2442.192138671875 slow_loss: 3083.587646484375\n",
      "iter: 40 loss: 6108.9697265625\n",
      "iter: 41 fast_loss: 2351.898193359375 slow_loss: 3205.329833984375\n",
      "iter: 41 loss: 6139.919921875\n",
      "iter: 42 fast_loss: 2404.0146484375 slow_loss: 3076.446533203125\n",
      "iter: 42 loss: 6063.154296875\n",
      "iter: 43 fast_loss: 2397.285400390625 slow_loss: 3019.317626953125\n",
      "iter: 43 loss: 5999.7958984375\n",
      "iter: 44 fast_loss: 2583.366455078125 slow_loss: 2819.160400390625\n",
      "iter: 44 loss: 5986.220703125\n",
      "iter: 45 fast_loss: 2355.194091796875 slow_loss: 2898.94873046875\n",
      "iter: 45 loss: 5832.83642578125\n",
      "iter: 46 fast_loss: 2771.232666015625 slow_loss: 2510.23876953125\n",
      "iter: 46 loss: 5858.1650390625\n",
      "iter: 47 fast_loss: 3046.16552734375 slow_loss: 2369.88818359375\n",
      "iter: 47 loss: 5992.4990234375\n",
      "iter: 48 fast_loss: 2766.082763671875 slow_loss: 2463.3408203125\n",
      "iter: 48 loss: 5804.62109375\n",
      "iter: 49 fast_loss: 2601.7685546875 slow_loss: 2671.53173828125\n",
      "iter: 49 loss: 5848.2490234375\n",
      "iter: 50 fast_loss: 2607.0556640625 slow_loss: 2807.96826171875\n",
      "iter: 50 loss: 5990.2236328125\n",
      "iter: 51 fast_loss: 2563.65966796875 slow_loss: 2623.19189453125\n",
      "iter: 51 loss: 5760.5517578125\n",
      "iter: 52 fast_loss: 2491.767822265625 slow_loss: 2561.05029296875\n",
      "iter: 52 loss: 5625.017578125\n",
      "iter: 53 fast_loss: 2459.6328125 slow_loss: 2787.506103515625\n",
      "iter: 53 loss: 5817.3388671875\n",
      "iter: 54 fast_loss: 2360.481201171875 slow_loss: 2936.370849609375\n",
      "iter: 54 loss: 5865.5517578125\n",
      "iter: 55 fast_loss: 2134.78076171875 slow_loss: 3262.7333984375\n",
      "iter: 55 loss: 5964.4638671875\n",
      "iter: 56 fast_loss: 2762.10009765625 slow_loss: 2999.267578125\n",
      "iter: 56 loss: 6326.06689453125\n",
      "iter: 57 fast_loss: 2659.721435546875 slow_loss: 3240.348876953125\n",
      "iter: 57 loss: 6467.0205078125\n",
      "iter: 58 fast_loss: 2429.42041015625 slow_loss: 3365.318359375\n",
      "iter: 58 loss: 6364.18701171875\n",
      "iter: 59 fast_loss: 2881.16455078125 slow_loss: 3252.433837890625\n",
      "iter: 59 loss: 6700.544921875\n",
      "iter: 60 fast_loss: 2802.47509765625 slow_loss: 3380.973876953125\n",
      "iter: 60 loss: 6747.89404296875\n",
      "iter: 61 fast_loss: 2150.093017578125 slow_loss: 3867.32470703125\n",
      "iter: 61 loss: 6581.11279296875\n",
      "iter: 62 fast_loss: 2352.859375 slow_loss: 3926.239013671875\n",
      "iter: 62 loss: 6845.294921875\n",
      "iter: 63 fast_loss: 2067.97021484375 slow_loss: 4227.951171875\n",
      "iter: 63 loss: 6865.869140625\n",
      "iter: 64 fast_loss: 1879.7607421875 slow_loss: 4541.40478515625\n",
      "iter: 64 loss: 6993.61279296875\n",
      "iter: 65 fast_loss: 2014.34326171875 slow_loss: 4499.65673828125\n",
      "iter: 65 loss: 7085.947265625\n",
      "iter: 66 fast_loss: 1651.1077880859375 slow_loss: 4954.28466796875\n",
      "iter: 66 loss: 7175.83984375\n",
      "iter: 67 fast_loss: 1451.4312744140625 slow_loss: 5244.4609375\n",
      "iter: 67 loss: 7264.84130859375\n",
      "iter: 68 fast_loss: 1499.97705078125 slow_loss: 5274.1240234375\n",
      "iter: 68 loss: 7342.8017578125\n",
      "iter: 69 fast_loss: 1618.560791015625 slow_loss: 5144.55419921875\n",
      "iter: 69 loss: 7331.81689453125\n",
      "iter: 70 fast_loss: 1436.943115234375 slow_loss: 5221.04638671875\n",
      "iter: 70 loss: 7226.693359375\n",
      "iter: 71 fast_loss: 1654.060302734375 slow_loss: 4993.7666015625\n",
      "iter: 71 loss: 7218.533203125\n",
      "iter: 72 fast_loss: 1676.3076171875 slow_loss: 5003.51708984375\n",
      "iter: 72 loss: 7252.033203125\n",
      "iter: 73 fast_loss: 1846.870361328125 slow_loss: 4928.60400390625\n",
      "iter: 73 loss: 7343.6845703125\n",
      "iter: 74 fast_loss: 1614.990234375 slow_loss: 5139.404296875\n",
      "iter: 74 loss: 7319.1064453125\n",
      "iter: 75 fast_loss: 1943.275390625 slow_loss: 4837.82958984375\n",
      "iter: 75 loss: 7345.06787109375\n",
      "iter: 76 fast_loss: 1851.3336181640625 slow_loss: 4878.1357421875\n",
      "iter: 76 loss: 7293.93359375\n",
      "iter: 77 fast_loss: 1991.6839599609375 slow_loss: 4705.4443359375\n",
      "iter: 77 loss: 7262.3427734375\n",
      "iter: 78 fast_loss: 1716.2705078125 slow_loss: 4999.671875\n",
      "iter: 78 loss: 7281.9072265625\n",
      "iter: 79 fast_loss: 1725.471435546875 slow_loss: 5044.16650390625\n",
      "iter: 79 loss: 7334.60302734375\n",
      "iter: 80 fast_loss: 1807.868896484375 slow_loss: 5185.40966796875\n",
      "iter: 80 loss: 7557.494140625\n",
      "iter: 81 fast_loss: 1793.9300537109375 slow_loss: 5379.38671875\n",
      "iter: 81 loss: 7738.0322265625\n",
      "iter: 82 fast_loss: 2384.99462890625 slow_loss: 4960.533203125\n",
      "iter: 82 loss: 7910.2431640625\n",
      "iter: 83 fast_loss: 1934.8984375 slow_loss: 5223.5869140625\n",
      "iter: 83 loss: 7722.20068359375\n",
      "iter: 84 fast_loss: 1295.219482421875 slow_loss: 5928.634765625\n",
      "iter: 84 loss: 7785.8193359375\n",
      "iter: 85 fast_loss: 1655.571044921875 slow_loss: 5718.58984375\n",
      "iter: 85 loss: 7934.3759765625\n",
      "iter: 86 fast_loss: 2211.479248046875 slow_loss: 5298.98046875\n",
      "iter: 86 loss: 8070.1748046875\n",
      "iter: 87 fast_loss: 1633.11767578125 slow_loss: 5631.591796875\n",
      "iter: 87 loss: 7824.9248046875\n",
      "iter: 88 fast_loss: 1758.56787109375 slow_loss: 5677.80322265625\n",
      "iter: 88 loss: 7995.5869140625\n",
      "iter: 89 fast_loss: 1543.853759765625 slow_loss: 5907.69189453125\n",
      "iter: 89 loss: 8008.7607421875\n",
      "iter: 90 fast_loss: 2329.65087890625 slow_loss: 5248.6494140625\n",
      "iter: 90 loss: 8134.51513671875\n",
      "iter: 91 fast_loss: 2323.127685546875 slow_loss: 5270.759765625\n",
      "iter: 91 loss: 8149.8525390625\n",
      "iter: 92 fast_loss: 1635.10888671875 slow_loss: 5883.1787109375\n",
      "iter: 92 loss: 8075.7529296875\n",
      "iter: 93 fast_loss: 2181.47265625 slow_loss: 5555.85498046875\n",
      "iter: 93 loss: 8295.04296875\n",
      "iter: 94 fast_loss: 1652.412353515625 slow_loss: 5880.294921875\n",
      "iter: 94 loss: 8088.046875\n",
      "iter: 95 fast_loss: 2288.79541015625 slow_loss: 5432.3271484375\n",
      "iter: 95 loss: 8273.9619140625\n",
      "iter: 96 fast_loss: 1731.5826416015625 slow_loss: 5947.03662109375\n",
      "iter: 96 loss: 8232.4580078125\n",
      "iter: 97 fast_loss: 2321.205078125 slow_loss: 5474.41845703125\n",
      "iter: 97 loss: 8347.587890625\n",
      "iter: 98 fast_loss: 1799.1485595703125 slow_loss: 5959.53369140625\n",
      "iter: 98 loss: 8307.8974609375\n",
      "iter: 99 fast_loss: 1642.79931640625 slow_loss: 6065.68896484375\n",
      "iter: 99 loss: 8257.953125\n",
      "iter: 100 fast_loss: 1791.389404296875 slow_loss: 5941.26904296875\n",
      "iter: 100 loss: 8282.1240234375\n",
      "usetime: 115.50553822517395\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win10\\AppData\\Local\\Temp\\ipykernel_9932\\4189447853.py:3: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n"
     ]
    }
   ],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "with open(file = \"neo0.txt\", mode = \"w\") as file:\n",
    "    for i in loss_li:\n",
    "        file.write(str(i)+\" \")\n",
    "    file.write(\"\\n\")\n",
    "    file.write(str(cur_times+1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x154abeb1430>]"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(100)]\n",
    "loss_li = [x/(cur_times+1) for x in loss_li]\n",
    "plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}