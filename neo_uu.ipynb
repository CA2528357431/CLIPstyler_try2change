{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork_uu import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model = Unet(device).to(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "# vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "# for x in vgg.parameters():\n",
    "#     x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "lr1 = 0.001\n",
    "lr2 = 0.0008\n",
    "\n",
    "# lr_fast = 0.0003\n",
    "# lr_slow = 0.0004\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 1\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "loss_li = []\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 50) == 0:\n",
    "        #     pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "\n",
    "    neo_pic = model(input)\n",
    "    pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    pil.save(f\"mid.jpg\")\n",
    "\n",
    "\n",
    "    # torch.save(model,'unet.pth')\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_fast = optim.Adam(model.parameters(), lr=lr_fast)\n",
    "    # opt_slow = optim.Adam(model.parameters(), lr=lr_slow)\n",
    "    # opt_loss = optim.Adam(cliploss.parameters(), lr=lr_slow)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # opt_slow.zero_grad()\n",
    "        # opt_fast.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "        # patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.get_image_prior_losses(neo_pic)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "\n",
    "        patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        patch_loss_fast *= patch_lambda\n",
    "        patch_loss_slow *= patch_lambda\n",
    "\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_fast.backward(retain_graph=True)\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_slow.backward(retain_graph=True)\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_li.append((loss+patch_loss_fast+patch_loss_slow).item())\n",
    "\n",
    "        print(\"iter:\", i + 1, \"fast_loss:\", patch_loss_fast.item(), \"slow_loss:\", patch_loss_slow.item())\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic2/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "pil = Image.open(f\"./source_pic/face2.jpeg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "source = \"photo\"\n",
    "# source = \"CG picture\"\n",
    "# source = \"human\"\n",
    "\n",
    "target = \"starry night by Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Monet\"\n",
    "# target = \"cyberpunk 2077\"\n",
    "# target = \"oil painting of flowers\"\n",
    "# target = \"neon light\"\n",
    "# target = \"The great wave off kanagawa by Hokusai\"\n",
    "# target = \"fire\"\n",
    "# target = \"Chinese Ink and wash painting\"\n",
    "# target = \"Expressionism\"\n",
    "# target = \"pencil painting\"\n",
    "# target = \"picasso\"\n",
    "# target = \"pop art of night city\"\n",
    "# target = \"wall paintings\"\n",
    "\n",
    "\n",
    "\n",
    "path = \"result.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.13712096214294434\n",
      "iter: 2 loss: 0.07515588402748108\n",
      "iter: 3 loss: 0.03946578875184059\n",
      "iter: 4 loss: 0.022640010342001915\n",
      "iter: 5 loss: 0.013683011755347252\n",
      "iter: 6 loss: 0.008645759895443916\n",
      "iter: 7 loss: 0.0056905923411250114\n",
      "iter: 8 loss: 0.004017006605863571\n",
      "iter: 9 loss: 0.003194700460880995\n",
      "iter: 10 loss: 0.002876584418118\n",
      "iter: 11 loss: 0.002769713755697012\n",
      "iter: 12 loss: 0.002718012547120452\n",
      "iter: 13 loss: 0.0026688016951084137\n",
      "iter: 14 loss: 0.0026251128874719143\n",
      "iter: 15 loss: 0.0025641275569796562\n",
      "iter: 16 loss: 0.0024642019998282194\n",
      "iter: 17 loss: 0.0023332955315709114\n",
      "iter: 18 loss: 0.0022154308389872313\n",
      "iter: 19 loss: 0.002127069979906082\n",
      "iter: 20 loss: 0.002062651328742504\n",
      "iter: 21 loss: 0.002006194554269314\n",
      "iter: 22 loss: 0.001948450691998005\n",
      "iter: 23 loss: 0.0018930111546069384\n",
      "iter: 24 loss: 0.001844789832830429\n",
      "iter: 25 loss: 0.0018088248325511813\n",
      "iter: 26 loss: 0.0017744551878422499\n",
      "iter: 27 loss: 0.0017378305783495307\n",
      "iter: 28 loss: 0.0016991490265354514\n",
      "iter: 29 loss: 0.0016561889788135886\n",
      "iter: 30 loss: 0.0016166928689926863\n",
      "iter: 31 loss: 0.0015773389022797346\n",
      "iter: 32 loss: 0.0015342257684096694\n",
      "iter: 33 loss: 0.0014914392959326506\n",
      "iter: 34 loss: 0.001448479713872075\n",
      "iter: 35 loss: 0.0014077529776841402\n",
      "iter: 36 loss: 0.0013668399769812822\n",
      "iter: 37 loss: 0.0013236519880592823\n",
      "iter: 38 loss: 0.0012790588662028313\n",
      "iter: 39 loss: 0.0012330412864685059\n",
      "iter: 40 loss: 0.0011877922806888819\n",
      "iter: 41 loss: 0.0011414634063839912\n",
      "iter: 42 loss: 0.0010951689910143614\n",
      "iter: 43 loss: 0.0010499110212549567\n",
      "iter: 44 loss: 0.001006199512630701\n",
      "iter: 45 loss: 0.0009680569637566805\n",
      "iter: 46 loss: 0.0009282872779294848\n",
      "iter: 47 loss: 0.0008900091052055359\n",
      "iter: 48 loss: 0.0008556760149076581\n",
      "iter: 49 loss: 0.0008260763133876026\n",
      "iter: 50 loss: 0.000800637761130929\n",
      "iter: 51 loss: 0.0007787533104419708\n",
      "iter: 52 loss: 0.0007578371441923082\n",
      "iter: 53 loss: 0.0007376483408734202\n",
      "iter: 54 loss: 0.000718087365385145\n",
      "iter: 55 loss: 0.0007018327014520764\n",
      "iter: 56 loss: 0.0006900447187945247\n",
      "iter: 57 loss: 0.0006800420815125108\n",
      "iter: 58 loss: 0.0006703737890347838\n",
      "iter: 59 loss: 0.0006620117928832769\n",
      "iter: 60 loss: 0.000653666618745774\n",
      "iter: 61 loss: 0.0006456367555074394\n",
      "iter: 62 loss: 0.0006393722724169493\n",
      "iter: 63 loss: 0.000632421812042594\n",
      "iter: 64 loss: 0.0006240062648430467\n",
      "iter: 65 loss: 0.0006147596286609769\n",
      "iter: 66 loss: 0.0006066523492336273\n",
      "iter: 67 loss: 0.0005976923275738955\n",
      "iter: 68 loss: 0.0005880746175535023\n",
      "iter: 69 loss: 0.0005797173362225294\n",
      "iter: 70 loss: 0.0005709920078516006\n",
      "iter: 71 loss: 0.0005626232596114278\n",
      "iter: 72 loss: 0.0005546481115743518\n",
      "iter: 73 loss: 0.0005482168635353446\n",
      "iter: 74 loss: 0.0005410714657045901\n",
      "iter: 75 loss: 0.0005350654828362167\n",
      "iter: 76 loss: 0.0005293207941576838\n",
      "iter: 77 loss: 0.0005224603228271008\n",
      "iter: 78 loss: 0.0005172986420802772\n",
      "iter: 79 loss: 0.0005114530213177204\n",
      "iter: 80 loss: 0.0005061328411102295\n",
      "iter: 81 loss: 0.0005010346649214625\n",
      "iter: 82 loss: 0.0004955118638463318\n",
      "iter: 83 loss: 0.0004901260836049914\n",
      "iter: 84 loss: 0.0004851088160648942\n",
      "iter: 85 loss: 0.00047972635366022587\n",
      "iter: 86 loss: 0.0004744819307234138\n",
      "iter: 87 loss: 0.0004698411503341049\n",
      "iter: 88 loss: 0.0004654869844671339\n",
      "iter: 89 loss: 0.0004605016147252172\n",
      "iter: 90 loss: 0.0004557098727673292\n",
      "iter: 91 loss: 0.00045077753020450473\n",
      "iter: 92 loss: 0.00044651509961113334\n",
      "iter: 93 loss: 0.0004419925098773092\n",
      "iter: 94 loss: 0.00043816815013997257\n",
      "iter: 95 loss: 0.0004343894252087921\n",
      "iter: 96 loss: 0.00042977993143722415\n",
      "iter: 97 loss: 0.00042617012513801455\n",
      "iter: 98 loss: 0.0004211871128063649\n",
      "iter: 99 loss: 0.0004180908144917339\n",
      "iter: 100 loss: 0.00041444491944275796\n",
      "iter: 1 fast_loss: 4034.797607421875 slow_loss: 5073.2119140625\n",
      "iter: 1 loss: 797.477294921875\n",
      "iter: 2 fast_loss: 4551.56689453125 slow_loss: 4196.84619140625\n",
      "iter: 2 loss: 744.0040283203125\n",
      "iter: 3 fast_loss: 4642.89111328125 slow_loss: 3864.166259765625\n",
      "iter: 3 loss: 738.5247802734375\n",
      "iter: 4 fast_loss: 4174.73583984375 slow_loss: 4142.4638671875\n",
      "iter: 4 loss: 728.54296875\n",
      "iter: 5 fast_loss: 4246.14697265625 slow_loss: 3951.850830078125\n",
      "iter: 5 loss: 723.3037719726562\n",
      "iter: 6 fast_loss: 3633.659423828125 slow_loss: 4373.86328125\n",
      "iter: 6 loss: 722.3169555664062\n",
      "iter: 7 fast_loss: 3995.452880859375 slow_loss: 3981.99462890625\n",
      "iter: 7 loss: 720.5814208984375\n",
      "iter: 8 fast_loss: 4659.02734375 slow_loss: 3169.487060546875\n",
      "iter: 8 loss: 711.8306884765625\n",
      "iter: 9 fast_loss: 4012.687744140625 slow_loss: 3737.9609375\n",
      "iter: 9 loss: 704.0750732421875\n",
      "iter: 10 fast_loss: 3639.9765625 slow_loss: 4090.34716796875\n",
      "iter: 10 loss: 704.580078125\n",
      "iter: 11 fast_loss: 3738.922119140625 slow_loss: 3933.7919921875\n",
      "iter: 11 loss: 701.8401489257812\n",
      "iter: 12 fast_loss: 4241.27197265625 slow_loss: 3465.568603515625\n",
      "iter: 12 loss: 699.6004028320312\n",
      "iter: 13 fast_loss: 4173.84326171875 slow_loss: 3419.28857421875\n",
      "iter: 13 loss: 698.3515625\n",
      "iter: 14 fast_loss: 3829.6279296875 slow_loss: 3807.44921875\n",
      "iter: 14 loss: 702.8502807617188\n",
      "iter: 15 fast_loss: 3954.185546875 slow_loss: 3680.488525390625\n",
      "iter: 15 loss: 705.60205078125\n",
      "iter: 16 fast_loss: 4150.08544921875 slow_loss: 3389.83154296875\n",
      "iter: 16 loss: 703.6036376953125\n",
      "iter: 17 fast_loss: 3800.03369140625 slow_loss: 3748.53515625\n",
      "iter: 17 loss: 702.600830078125\n",
      "iter: 18 fast_loss: 4118.98046875 slow_loss: 3350.1435546875\n",
      "iter: 18 loss: 700.6004638671875\n",
      "iter: 19 fast_loss: 4008.979736328125 slow_loss: 3520.294189453125\n",
      "iter: 19 loss: 699.8515625\n",
      "iter: 20 fast_loss: 4016.94482421875 slow_loss: 3494.3388671875\n",
      "iter: 20 loss: 705.1017456054688\n",
      "iter: 21 fast_loss: 4250.6103515625 slow_loss: 3268.4326171875\n",
      "iter: 21 loss: 702.3533935546875\n",
      "iter: 22 fast_loss: 3987.419189453125 slow_loss: 3492.9658203125\n",
      "iter: 22 loss: 694.1055908203125\n",
      "iter: 23 fast_loss: 3890.39599609375 slow_loss: 3578.59033203125\n",
      "iter: 23 loss: 690.1102294921875\n",
      "iter: 24 fast_loss: 3265.47998046875 slow_loss: 4157.15771484375\n",
      "iter: 24 loss: 690.3628540039062\n",
      "iter: 25 fast_loss: 4279.93017578125 slow_loss: 3102.126953125\n",
      "iter: 25 loss: 691.6127319335938\n",
      "iter: 26 fast_loss: 3284.431396484375 slow_loss: 4157.4326171875\n",
      "iter: 26 loss: 693.1126708984375\n",
      "iter: 27 fast_loss: 3943.95458984375 slow_loss: 3440.16259765625\n",
      "iter: 27 loss: 693.121826171875\n",
      "iter: 28 fast_loss: 3575.981201171875 slow_loss: 3780.94482421875\n",
      "iter: 28 loss: 690.3824462890625\n",
      "iter: 29 fast_loss: 3470.03173828125 slow_loss: 3904.19775390625\n",
      "iter: 29 loss: 694.8863525390625\n",
      "iter: 30 fast_loss: 3945.6025390625 slow_loss: 3435.28759765625\n",
      "iter: 30 loss: 691.6412353515625\n",
      "iter: 31 fast_loss: 3229.362548828125 slow_loss: 4113.28125\n",
      "iter: 31 loss: 690.394775390625\n",
      "iter: 32 fast_loss: 3761.9248046875 slow_loss: 3508.07177734375\n",
      "iter: 32 loss: 691.8955078125\n",
      "iter: 33 fast_loss: 3089.767578125 slow_loss: 4186.271484375\n",
      "iter: 33 loss: 684.14599609375\n",
      "iter: 34 fast_loss: 3424.64453125 slow_loss: 3830.38330078125\n",
      "iter: 34 loss: 686.395751953125\n",
      "iter: 35 fast_loss: 3986.0458984375 slow_loss: 3278.1142578125\n",
      "iter: 35 loss: 687.1494140625\n",
      "iter: 36 fast_loss: 3659.68310546875 slow_loss: 3614.433349609375\n",
      "iter: 36 loss: 687.650390625\n",
      "iter: 37 fast_loss: 3297.34033203125 slow_loss: 3941.34521484375\n",
      "iter: 37 loss: 688.8985595703125\n",
      "iter: 38 fast_loss: 3988.2431640625 slow_loss: 3293.35791015625\n",
      "iter: 38 loss: 690.3975830078125\n",
      "iter: 39 fast_loss: 3339.70654296875 slow_loss: 3969.90966796875\n",
      "iter: 39 loss: 683.6441650390625\n",
      "iter: 40 fast_loss: 3751.8310546875 slow_loss: 3505.53125\n",
      "iter: 40 loss: 675.6433715820312\n",
      "iter: 41 fast_loss: 3768.310546875 slow_loss: 3455.40625\n",
      "iter: 41 loss: 682.642333984375\n",
      "iter: 42 fast_loss: 3749.08447265625 slow_loss: 3468.93310546875\n",
      "iter: 42 loss: 683.39111328125\n",
      "iter: 43 fast_loss: 3547.8974609375 slow_loss: 3736.381591796875\n",
      "iter: 43 loss: 690.3953857421875\n",
      "iter: 44 fast_loss: 4045.30322265625 slow_loss: 3116.615234375\n",
      "iter: 44 loss: 684.6453857421875\n",
      "iter: 45 fast_loss: 4070.228515625 slow_loss: 3105.903564453125\n",
      "iter: 45 loss: 683.6421508789062\n",
      "iter: 46 fast_loss: 3182.39599609375 slow_loss: 4029.78515625\n",
      "iter: 46 loss: 682.8959350585938\n",
      "iter: 47 fast_loss: 4085.8154296875 slow_loss: 3132.408203125\n",
      "iter: 47 loss: 678.4000854492188\n",
      "iter: 48 fast_loss: 3749.83984375 slow_loss: 3460.693359375\n",
      "iter: 48 loss: 675.897216796875\n",
      "iter: 49 fast_loss: 3362.57177734375 slow_loss: 3783.69140625\n",
      "iter: 49 loss: 672.3970947265625\n",
      "iter: 50 fast_loss: 3262.52734375 slow_loss: 3902.618408203125\n",
      "iter: 50 loss: 677.647216796875\n",
      "iter: 51 fast_loss: 3844.940185546875 slow_loss: 3358.039794921875\n",
      "iter: 51 loss: 683.1429443359375\n",
      "iter: 52 fast_loss: 3699.028076171875 slow_loss: 3422.79052734375\n",
      "iter: 52 loss: 674.6395874023438\n",
      "iter: 53 fast_loss: 3584.97607421875 slow_loss: 3557.92236328125\n",
      "iter: 53 loss: 674.8836669921875\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n",
    "\n",
    "\n",
    "\n",
    "# 186.4968602657318\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with open(file = \"neo0.txt\", mode = \"w\") as file:\n",
    "#     for i in loss_li:\n",
    "#         file.write(str(i)+\" \")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(100)]\n",
    "plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}