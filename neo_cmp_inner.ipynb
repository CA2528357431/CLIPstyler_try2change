{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork_uu import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lr1 = 0.0002\n",
    "lr2 = 0.0002\n",
    "model = Unet(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "for x in vgg.parameters():\n",
    "    x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 150\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "loss_li = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target, path):\n",
    "    input = pic\n",
    "\n",
    "    # opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    # for i in range(iteration1):\n",
    "    #     opt.zero_grad()\n",
    "    #     neo_pic = model(input)\n",
    "    #     loss = mseloss(pic, neo_pic) * 1\n",
    "    #     loss.backward()\n",
    "    #     opt.step()\n",
    "    #     pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    #     print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "    #     if ((i + 1) % 50) == 0:\n",
    "    #         pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "    #\n",
    "    #\n",
    "    # torch.save(model,'unet.pth')\n",
    "    #\n",
    "    # cliploss.fc.requires_grad = False\n",
    "    # for x in cliploss.fc.block.parameters():\n",
    "    #     x.requires_grad = False\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "        # content_loss += mseloss(pic,neo_pic)\n",
    "\n",
    "        patch_loss = 0\n",
    "        # patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.get_image_prior_losses(neo_pic)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "        patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "\n",
    "        patch_loss_fast *= patch_lambda\n",
    "        patch_loss_slow *= patch_lambda\n",
    "\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_fast.backward(retain_graph=True)\n",
    "        for x in model.res2.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = False\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = False\n",
    "        patch_loss_slow.backward(retain_graph=True)\n",
    "        for x in model.res.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.conv3.parameters():\n",
    "            x.requires_grad = True\n",
    "        for x in model.upsample3.parameters():\n",
    "            x.requires_grad = True\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_li.append((loss+patch_loss_fast+patch_loss_slow).item())\n",
    "\n",
    "            print(\"iter:\", i + 1, \"fast_loss:\", patch_loss_fast.item(), \"slow_loss:\", patch_loss_slow.item())\n",
    "            print(\"iter:\", i + 1, \"loss:\", (loss+patch_loss_fast+patch_loss_slow).item())\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic3/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "pil = Image.open(f\"./source_pic/church.jpeg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "source = \"photo\"\n",
    "target = \"pop art of night city\"\n",
    "# target = \"Chinese Ink and wash painting\"\n",
    "# target = \"starry night by Van Gogh\"\n",
    "# target = \"the scream by Edvard Munch\"\n",
    "# target = \"Monet\"\n",
    "# target = \"cyberpunk 2077\"\n",
    "path = \"result2.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 fast_loss: 4456.0546875 slow_loss: 4090.75927734375\n",
      "iter: 1 loss: 10983.52734375\n",
      "iter: 2 fast_loss: 4286.79638671875 slow_loss: 3969.291748046875\n",
      "iter: 2 loss: 10544.16796875\n",
      "iter: 3 fast_loss: 4298.263671875 slow_loss: 3748.603759765625\n",
      "iter: 3 loss: 10221.9541015625\n",
      "iter: 4 fast_loss: 4484.75634765625 slow_loss: 3450.94287109375\n",
      "iter: 4 loss: 10055.0\n",
      "iter: 5 fast_loss: 4159.904296875 slow_loss: 3641.21240234375\n",
      "iter: 5 loss: 9878.603515625\n",
      "iter: 6 fast_loss: 4208.72509765625 slow_loss: 3465.019287109375\n",
      "iter: 6 loss: 9728.9853515625\n",
      "iter: 7 fast_loss: 3805.595458984375 slow_loss: 3759.590087890625\n",
      "iter: 7 loss: 9594.94921875\n",
      "iter: 8 fast_loss: 4600.3876953125 slow_loss: 2923.11865234375\n",
      "iter: 8 loss: 9538.626953125\n",
      "iter: 9 fast_loss: 3753.204345703125 slow_loss: 3712.211669921875\n",
      "iter: 9 loss: 9459.3486328125\n",
      "iter: 10 fast_loss: 3836.357177734375 slow_loss: 3516.517578125\n",
      "iter: 10 loss: 9321.10546875\n",
      "iter: 11 fast_loss: 4285.7666015625 slow_loss: 3088.05078125\n",
      "iter: 11 loss: 9314.5771484375\n",
      "iter: 12 fast_loss: 4150.97802734375 slow_loss: 3202.5146484375\n",
      "iter: 12 loss: 9264.978515625\n",
      "iter: 13 fast_loss: 3993.66748046875 slow_loss: 3291.16064453125\n",
      "iter: 13 loss: 9169.365234375\n",
      "iter: 14 fast_loss: 3837.799072265625 slow_loss: 3323.7763671875\n",
      "iter: 14 loss: 9026.8466796875\n",
      "iter: 15 fast_loss: 3513.908447265625 slow_loss: 3703.697265625\n",
      "iter: 15 loss: 9061.958984375\n",
      "iter: 16 fast_loss: 3601.45556640625 slow_loss: 3545.2880859375\n",
      "iter: 16 loss: 8967.3388671875\n",
      "iter: 17 fast_loss: 3928.436279296875 slow_loss: 3186.79052734375\n",
      "iter: 17 loss: 8911.966796875\n",
      "iter: 18 fast_loss: 3670.600830078125 slow_loss: 3399.3759765625\n",
      "iter: 18 loss: 8840.7734375\n",
      "iter: 19 fast_loss: 3325.5615234375 slow_loss: 3724.090576171875\n",
      "iter: 19 loss: 8797.23828125\n",
      "iter: 20 fast_loss: 3414.962890625 slow_loss: 3548.03466796875\n",
      "iter: 20 loss: 8690.119140625\n",
      "iter: 21 fast_loss: 3591.63671875 slow_loss: 3330.436767578125\n",
      "iter: 21 loss: 8621.57421875\n",
      "iter: 22 fast_loss: 3599.052490234375 slow_loss: 3307.296875\n",
      "iter: 22 loss: 8582.2607421875\n",
      "iter: 23 fast_loss: 3678.97802734375 slow_loss: 3207.389892578125\n",
      "iter: 23 loss: 8542.4267578125\n",
      "iter: 24 fast_loss: 3262.939453125 slow_loss: 3640.31982421875\n",
      "iter: 24 loss: 8530.3125\n",
      "iter: 25 fast_loss: 3433.43359375 slow_loss: 3377.74658203125\n",
      "iter: 25 loss: 8417.169921875\n",
      "iter: 26 fast_loss: 3318.145751953125 slow_loss: 3491.386474609375\n",
      "iter: 26 loss: 8392.8515625\n",
      "iter: 27 fast_loss: 3945.808349609375 slow_loss: 2824.1728515625\n",
      "iter: 27 loss: 8331.1806640625\n",
      "iter: 28 fast_loss: 3609.35205078125 slow_loss: 3124.85498046875\n",
      "iter: 28 loss: 8274.8759765625\n",
      "iter: 29 fast_loss: 3501.89208984375 slow_loss: 3249.00048828125\n",
      "iter: 29 loss: 8274.736328125\n",
      "iter: 30 fast_loss: 2878.28076171875 slow_loss: 3868.97265625\n",
      "iter: 30 loss: 8256.15234375\n",
      "iter: 31 fast_loss: 3371.772705078125 slow_loss: 3314.02587890625\n",
      "iter: 31 loss: 8176.72216796875\n",
      "iter: 32 fast_loss: 3447.16650390625 slow_loss: 3187.33984375\n",
      "iter: 32 loss: 8107.25634765625\n",
      "iter: 33 fast_loss: 3348.08349609375 slow_loss: 3349.86865234375\n",
      "iter: 33 loss: 8158.18603515625\n",
      "iter: 34 fast_loss: 3637.5732421875 slow_loss: 3000.91552734375\n",
      "iter: 34 loss: 8085.88623046875\n",
      "iter: 35 fast_loss: 3735.832275390625 slow_loss: 2856.376708984375\n",
      "iter: 35 loss: 8026.55859375\n",
      "iter: 36 fast_loss: 3297.75244140625 slow_loss: 3262.52734375\n",
      "iter: 36 loss: 7983.58740234375\n",
      "iter: 37 fast_loss: 3205.6044921875 slow_loss: 3374.725341796875\n",
      "iter: 37 loss: 7990.7744140625\n",
      "iter: 38 fast_loss: 3499.214111328125 slow_loss: 3055.778564453125\n",
      "iter: 38 loss: 7952.400390625\n",
      "iter: 39 fast_loss: 3405.89892578125 slow_loss: 3171.684326171875\n",
      "iter: 39 loss: 7960.87890625\n",
      "iter: 40 fast_loss: 3683.921875 slow_loss: 2850.5400390625\n",
      "iter: 40 loss: 7907.31591796875\n",
      "iter: 41 fast_loss: 3167.70166015625 slow_loss: 3336.067138671875\n",
      "iter: 41 loss: 7867.86328125\n",
      "iter: 42 fast_loss: 3170.379638671875 slow_loss: 3347.87744140625\n",
      "iter: 42 loss: 7875.57763671875\n",
      "iter: 43 fast_loss: 3558.952392578125 slow_loss: 2916.595458984375\n",
      "iter: 43 loss: 7817.220703125\n",
      "iter: 44 fast_loss: 3240.5546875 slow_loss: 3211.7158203125\n",
      "iter: 44 loss: 7781.8955078125\n",
      "iter: 45 fast_loss: 2922.431884765625 slow_loss: 3492.759765625\n",
      "iter: 45 loss: 7734.8330078125\n",
      "iter: 46 fast_loss: 3357.07861328125 slow_loss: 3127.12109375\n",
      "iter: 46 loss: 7796.4619140625\n",
      "iter: 47 fast_loss: 3057.426513671875 slow_loss: 3414.619384765625\n",
      "iter: 47 loss: 7776.42578125\n",
      "iter: 48 fast_loss: 3241.92822265625 slow_loss: 3211.44091796875\n",
      "iter: 48 loss: 7752.09228515625\n",
      "iter: 49 fast_loss: 3510.1318359375 slow_loss: 2881.5078125\n",
      "iter: 49 loss: 7685.2041015625\n",
      "iter: 50 fast_loss: 3192.28369140625 slow_loss: 3181.640625\n",
      "iter: 50 loss: 7661.9892578125\n",
      "iter: 51 fast_loss: 3607.2236328125 slow_loss: 2786.201416015625\n",
      "iter: 51 loss: 7676.4482421875\n",
      "iter: 52 fast_loss: 3112.56396484375 slow_loss: 3296.44775390625\n",
      "iter: 52 loss: 7679.36962890625\n",
      "iter: 53 fast_loss: 3281.2041015625 slow_loss: 3055.366455078125\n",
      "iter: 53 loss: 7600.1962890625\n",
      "iter: 54 fast_loss: 2870.59033203125 slow_loss: 3434.66943359375\n",
      "iter: 54 loss: 7568.02783203125\n",
      "iter: 55 fast_loss: 3297.54638671875 slow_loss: 3071.0908203125\n",
      "iter: 55 loss: 7627.1005859375\n",
      "iter: 56 fast_loss: 3765.083251953125 slow_loss: 2555.76318359375\n",
      "iter: 56 loss: 7573.52490234375\n",
      "iter: 57 fast_loss: 3274.337890625 slow_loss: 3077.81982421875\n",
      "iter: 57 loss: 7601.19775390625\n",
      "iter: 58 fast_loss: 2904.510498046875 slow_loss: 3463.302734375\n",
      "iter: 58 loss: 7609.42919921875\n",
      "iter: 59 fast_loss: 3308.12060546875 slow_loss: 2924.079833984375\n",
      "iter: 59 loss: 7469.529296875\n",
      "iter: 60 fast_loss: 3227.02783203125 slow_loss: 3035.041748046875\n",
      "iter: 60 loss: 7493.521484375\n",
      "iter: 61 fast_loss: 3203.4072265625 slow_loss: 3011.283935546875\n",
      "iter: 61 loss: 7436.845703125\n",
      "iter: 62 fast_loss: 3342.38427734375 slow_loss: 2917.488037109375\n",
      "iter: 62 loss: 7479.7158203125\n",
      "iter: 63 fast_loss: 3048.912109375 slow_loss: 3220.710693359375\n",
      "iter: 63 loss: 7493.7333984375\n",
      "iter: 64 fast_loss: 3515.212890625 slow_loss: 2710.533203125\n",
      "iter: 64 loss: 7453.0654296875\n",
      "iter: 65 fast_loss: 2725.433349609375 slow_loss: 3511.23046875\n",
      "iter: 65 loss: 7462.283203125\n",
      "iter: 66 fast_loss: 2949.142578125 slow_loss: 3328.857421875\n",
      "iter: 66 loss: 7498.556640625\n",
      "iter: 67 fast_loss: 2821.4951171875 slow_loss: 3411.735595703125\n",
      "iter: 67 loss: 7444.16552734375\n",
      "iter: 68 fast_loss: 3013.20654296875 slow_loss: 3178.619384765625\n",
      "iter: 68 loss: 7399.58984375\n",
      "iter: 69 fast_loss: 2720.07763671875 slow_loss: 3478.752197265625\n",
      "iter: 69 loss: 7399.6337890625\n",
      "iter: 70 fast_loss: 2821.220458984375 slow_loss: 3385.64306640625\n",
      "iter: 70 loss: 7405.56298828125\n",
      "iter: 71 fast_loss: 3005.378662109375 slow_loss: 3194.82421875\n",
      "iter: 71 loss: 7398.068359375\n",
      "iter: 72 fast_loss: 3174.980224609375 slow_loss: 2968.16259765625\n",
      "iter: 72 loss: 7339.87451171875\n",
      "iter: 73 fast_loss: 3090.11083984375 slow_loss: 3066.6962890625\n",
      "iter: 73 loss: 7341.45458984375\n",
      "iter: 74 fast_loss: 3397.72802734375 slow_loss: 2784.965576171875\n",
      "iter: 74 loss: 7350.4814453125\n",
      "iter: 75 fast_loss: 2887.55029296875 slow_loss: 3294.66259765625\n",
      "iter: 75 loss: 7343.98779296875\n",
      "iter: 76 fast_loss: 3202.789306640625 slow_loss: 2970.085205078125\n",
      "iter: 76 loss: 7333.12109375\n",
      "iter: 77 fast_loss: 3273.7197265625 slow_loss: 2860.015869140625\n",
      "iter: 77 loss: 7296.9619140625\n",
      "iter: 78 fast_loss: 2894.69140625 slow_loss: 3238.5634765625\n",
      "iter: 78 loss: 7297.9921875\n",
      "iter: 79 fast_loss: 3489.9443359375 slow_loss: 2696.868896484375\n",
      "iter: 79 loss: 7351.171875\n",
      "iter: 80 fast_loss: 3376.85400390625 slow_loss: 2768.7607421875\n",
      "iter: 80 loss: 7305.521484375\n",
      "iter: 81 fast_loss: 3274.955810546875 slow_loss: 2842.02587890625\n",
      "iter: 81 loss: 7275.42041015625\n",
      "iter: 82 fast_loss: 3299.74365234375 slow_loss: 2875.602783203125\n",
      "iter: 82 loss: 7336.0224609375\n",
      "iter: 83 fast_loss: 3067.863525390625 slow_loss: 3069.44287109375\n",
      "iter: 83 loss: 7297.36083984375\n",
      "iter: 84 fast_loss: 2813.94189453125 slow_loss: 3352.8212890625\n",
      "iter: 84 loss: 7321.30908203125\n",
      "iter: 85 fast_loss: 2780.77685546875 slow_loss: 3357.147216796875\n",
      "iter: 85 loss: 7286.45703125\n",
      "iter: 86 fast_loss: 3170.928955078125 slow_loss: 2952.094970703125\n",
      "iter: 86 loss: 7264.158203125\n",
      "iter: 87 fast_loss: 2869.97216796875 slow_loss: 3249.61865234375\n",
      "iter: 87 loss: 7256.234375\n",
      "iter: 88 fast_loss: 3061.8896484375 slow_loss: 3081.87109375\n",
      "iter: 88 loss: 7281.228515625\n",
      "iter: 89 fast_loss: 3130.55419921875 slow_loss: 2919.891357421875\n",
      "iter: 89 loss: 7186.529296875\n",
      "iter: 90 fast_loss: 2858.23046875 slow_loss: 3220.298828125\n",
      "iter: 90 loss: 7210.85498046875\n",
      "iter: 91 fast_loss: 3059.14306640625 slow_loss: 3059.8984375\n",
      "iter: 91 loss: 7250.7978515625\n",
      "iter: 92 fast_loss: 2775.215087890625 slow_loss: 3329.681396484375\n",
      "iter: 92 loss: 7232.3408203125\n",
      "iter: 93 fast_loss: 3140.78515625 slow_loss: 2933.624267578125\n",
      "iter: 93 loss: 7199.251953125\n",
      "iter: 94 fast_loss: 2764.778076171875 slow_loss: 3285.186767578125\n",
      "iter: 94 loss: 7172.74609375\n",
      "iter: 95 fast_loss: 3322.81494140625 slow_loss: 2723.0986328125\n",
      "iter: 95 loss: 7165.3994140625\n",
      "iter: 96 fast_loss: 2662.605224609375 slow_loss: 3423.33984375\n",
      "iter: 96 loss: 7202.22509765625\n",
      "iter: 97 fast_loss: 2931.8388671875 slow_loss: 3127.46435546875\n",
      "iter: 97 loss: 7171.8876953125\n",
      "iter: 98 fast_loss: 3063.1943359375 slow_loss: 3034.492431640625\n",
      "iter: 98 loss: 7219.359375\n",
      "iter: 99 fast_loss: 3207.389892578125 slow_loss: 2847.930908203125\n",
      "iter: 99 loss: 7179.994140625\n",
      "iter: 100 fast_loss: 3403.01513671875 slow_loss: 2675.30810546875\n",
      "iter: 100 loss: 7196.18212890625\n",
      "iter: 101 fast_loss: 3008.7431640625 slow_loss: 3027.419921875\n",
      "iter: 101 loss: 7147.6142578125\n",
      "iter: 102 fast_loss: 2842.094482421875 slow_loss: 3196.26611328125\n",
      "iter: 102 loss: 7149.63623046875\n",
      "iter: 103 fast_loss: 3129.66162109375 slow_loss: 2917.21337890625\n",
      "iter: 103 loss: 7159.60302734375\n",
      "iter: 104 fast_loss: 3044.7236328125 slow_loss: 3023.4375\n",
      "iter: 104 loss: 7184.28466796875\n",
      "iter: 105 fast_loss: 3041.7021484375 slow_loss: 3026.802001953125\n",
      "iter: 105 loss: 7186.61328125\n",
      "iter: 106 fast_loss: 3027.96923828125 slow_loss: 3013.20654296875\n",
      "iter: 106 loss: 7154.15576171875\n",
      "iter: 107 fast_loss: 3026.802001953125 slow_loss: 3031.5400390625\n",
      "iter: 107 loss: 7165.6748046875\n",
      "iter: 108 fast_loss: 2849.029541015625 slow_loss: 3230.32373046875\n",
      "iter: 108 loss: 7184.0634765625\n",
      "iter: 109 fast_loss: 3186.79052734375 slow_loss: 2815.3837890625\n",
      "iter: 109 loss: 7106.107421875\n",
      "iter: 110 fast_loss: 3193.38232421875 slow_loss: 2816.070556640625\n",
      "iter: 110 loss: 7112.345703125\n",
      "iter: 111 fast_loss: 3090.66015625 slow_loss: 2898.53662109375\n",
      "iter: 111 loss: 7089.4921875\n",
      "iter: 112 fast_loss: 2901.008544921875 slow_loss: 3085.029541015625\n",
      "iter: 112 loss: 7081.30810546875\n",
      "iter: 113 fast_loss: 2623.809814453125 slow_loss: 3372.871337890625\n",
      "iter: 113 loss: 7090.0771484375\n",
      "iter: 114 fast_loss: 3060.173095703125 slow_loss: 2884.8037109375\n",
      "iter: 114 loss: 7041.814453125\n",
      "iter: 115 fast_loss: 3002.90673828125 slow_loss: 2988.0751953125\n",
      "iter: 115 loss: 7092.3662109375\n",
      "iter: 116 fast_loss: 2594.55859375 slow_loss: 3362.640380859375\n",
      "iter: 116 loss: 7060.404296875\n",
      "iter: 117 fast_loss: 2799.041748046875 slow_loss: 3177.314697265625\n",
      "iter: 117 loss: 7075.2021484375\n",
      "iter: 118 fast_loss: 2874.36669921875 slow_loss: 3061.8896484375\n",
      "iter: 118 loss: 7030.79638671875\n",
      "iter: 119 fast_loss: 2975.64697265625 slow_loss: 3011.970458984375\n",
      "iter: 119 loss: 7081.3857421875\n",
      "iter: 120 fast_loss: 3050.422607421875 slow_loss: 2895.515380859375\n",
      "iter: 120 loss: 7038.2607421875\n",
      "iter: 121 fast_loss: 2722.06884765625 slow_loss: 3268.4326171875\n",
      "iter: 121 loss: 7080.85009765625\n",
      "iter: 122 fast_loss: 3061.75244140625 slow_loss: 2883.705078125\n",
      "iter: 122 loss: 7032.705078125\n",
      "iter: 123 fast_loss: 2611.31298828125 slow_loss: 3370.46826171875\n",
      "iter: 123 loss: 7066.123046875\n",
      "iter: 124 fast_loss: 2788.055419921875 slow_loss: 3179.511962890625\n",
      "iter: 124 loss: 7044.431640625\n",
      "iter: 125 fast_loss: 3171.135009765625 slow_loss: 2812.431396484375\n",
      "iter: 125 loss: 7053.310546875\n",
      "iter: 126 fast_loss: 3239.044189453125 slow_loss: 2705.24609375\n",
      "iter: 126 loss: 7012.3515625\n",
      "iter: 127 fast_loss: 3051.7958984375 slow_loss: 2905.403076171875\n",
      "iter: 127 loss: 7026.74609375\n",
      "iter: 128 fast_loss: 3223.80078125 slow_loss: 2700.09619140625\n",
      "iter: 128 loss: 6997.2705078125\n",
      "iter: 129 fast_loss: 3091.00341796875 slow_loss: 2916.8701171875\n",
      "iter: 129 loss: 7083.47265625\n",
      "iter: 130 fast_loss: 2769.584716796875 slow_loss: 3135.2919921875\n",
      "iter: 130 loss: 6975.4501953125\n",
      "iter: 131 fast_loss: 2767.25 slow_loss: 3139.2060546875\n",
      "iter: 131 loss: 6968.64453125\n",
      "iter: 132 fast_loss: 3067.3828125 slow_loss: 2875.46533203125\n",
      "iter: 132 loss: 7001.42431640625\n",
      "iter: 133 fast_loss: 2487.785400390625 slow_loss: 3437.416015625\n",
      "iter: 133 loss: 6981.82958984375\n",
      "iter: 134 fast_loss: 3219.612060546875 slow_loss: 2674.96484375\n",
      "iter: 134 loss: 6949.45068359375\n",
      "iter: 135 fast_loss: 2501.03759765625 slow_loss: 3416.0615234375\n",
      "iter: 135 loss: 6974.1328125\n",
      "iter: 136 fast_loss: 2860.6337890625 slow_loss: 3037.101806640625\n",
      "iter: 136 loss: 6957.9462890625\n",
      "iter: 137 fast_loss: 2502.067626953125 slow_loss: 3396.42333984375\n",
      "iter: 137 loss: 6954.37841796875\n",
      "iter: 138 fast_loss: 2700.30224609375 slow_loss: 3272.68994140625\n",
      "iter: 138 loss: 7025.8662109375\n",
      "iter: 139 fast_loss: 2951.8203125 slow_loss: 2951.408447265625\n",
      "iter: 139 loss: 6952.650390625\n",
      "iter: 140 fast_loss: 2769.447265625 slow_loss: 3181.022705078125\n",
      "iter: 140 loss: 6999.5078125\n",
      "iter: 141 fast_loss: 2765.2587890625 slow_loss: 3121.76513671875\n",
      "iter: 141 loss: 6938.798828125\n",
      "iter: 142 fast_loss: 2548.210205078125 slow_loss: 3306.404052734375\n",
      "iter: 142 loss: 6904.4951171875\n",
      "iter: 143 fast_loss: 3019.79833984375 slow_loss: 2865.234375\n",
      "iter: 143 loss: 6932.52978515625\n",
      "iter: 144 fast_loss: 3073.150634765625 slow_loss: 2902.862548828125\n",
      "iter: 144 loss: 7024.4140625\n",
      "iter: 145 fast_loss: 2795.402587890625 slow_loss: 3146.484375\n",
      "iter: 145 loss: 6995.29638671875\n",
      "iter: 146 fast_loss: 3140.64794921875 slow_loss: 2781.18896484375\n",
      "iter: 146 loss: 6979.7060546875\n",
      "iter: 147 fast_loss: 2836.601318359375 slow_loss: 3041.56494140625\n",
      "iter: 147 loss: 6933.1826171875\n",
      "iter: 148 fast_loss: 2765.327392578125 slow_loss: 3143.94384765625\n",
      "iter: 148 loss: 6962.283203125\n",
      "iter: 149 fast_loss: 3418.18994140625 slow_loss: 2509.758056640625\n",
      "iter: 149 loss: 6983.8447265625\n",
      "iter: 150 fast_loss: 3142.913818359375 slow_loss: 2787.57470703125\n",
      "iter: 150 loss: 6989.61669921875\n",
      "iter: 151 fast_loss: 2760.177734375 slow_loss: 3149.986328125\n",
      "iter: 151 loss: 6976.3896484375\n",
      "iter: 152 fast_loss: 2885.2158203125 slow_loss: 3107.551513671875\n",
      "iter: 152 loss: 7054.7724609375\n",
      "iter: 153 fast_loss: 2877.593994140625 slow_loss: 3023.162841796875\n",
      "iter: 153 loss: 6954.9697265625\n",
      "iter: 154 fast_loss: 2991.508544921875 slow_loss: 2995.697021484375\n",
      "iter: 154 loss: 7035.94921875\n",
      "iter: 155 fast_loss: 2865.78369140625 slow_loss: 3065.666259765625\n",
      "iter: 155 loss: 6973.8349609375\n",
      "iter: 156 fast_loss: 2846.5576171875 slow_loss: 3035.453857421875\n",
      "iter: 156 loss: 6922.123046875\n",
      "iter: 157 fast_loss: 3247.489990234375 slow_loss: 2656.90625\n",
      "iter: 157 loss: 6948.341796875\n",
      "iter: 158 fast_loss: 2312.27880859375 slow_loss: 3598.708984375\n",
      "iter: 158 loss: 6958.09130859375\n",
      "iter: 159 fast_loss: 3506.011962890625 slow_loss: 2423.99609375\n",
      "iter: 159 loss: 6977.66064453125\n",
      "iter: 160 fast_loss: 2769.79052734375 slow_loss: 3143.39453125\n",
      "iter: 160 loss: 6958.091796875\n",
      "iter: 161 fast_loss: 2744.72802734375 slow_loss: 3188.0263671875\n",
      "iter: 161 loss: 6974.60546875\n",
      "iter: 162 fast_loss: 3049.5986328125 slow_loss: 2866.813720703125\n",
      "iter: 162 loss: 6959.197265625\n",
      "iter: 163 fast_loss: 2821.220458984375 slow_loss: 3028.0380859375\n",
      "iter: 163 loss: 6893.35400390625\n",
      "iter: 164 fast_loss: 3115.997314453125 slow_loss: 2799.31640625\n",
      "iter: 164 loss: 6963.1689453125\n",
      "iter: 165 fast_loss: 2884.66650390625 slow_loss: 3065.116943359375\n",
      "iter: 165 loss: 6992.353515625\n",
      "iter: 166 fast_loss: 3075.21044921875 slow_loss: 2862.89990234375\n",
      "iter: 166 loss: 6981.68408203125\n",
      "iter: 167 fast_loss: 2321.205078125 slow_loss: 3629.1962890625\n",
      "iter: 167 loss: 6993.744140625\n",
      "iter: 168 fast_loss: 3156.578125 slow_loss: 2801.7197265625\n",
      "iter: 168 loss: 7008.90771484375\n",
      "iter: 169 fast_loss: 2951.88916015625 slow_loss: 2931.70166015625\n",
      "iter: 169 loss: 6935.17138671875\n",
      "iter: 170 fast_loss: 3688.65966796875 slow_loss: 2224.662841796875\n",
      "iter: 170 loss: 6962.8388671875\n",
      "iter: 171 fast_loss: 2945.29736328125 slow_loss: 2951.68310546875\n",
      "iter: 171 loss: 6946.4765625\n",
      "iter: 172 fast_loss: 2641.7998046875 slow_loss: 3210.75439453125\n",
      "iter: 172 loss: 6898.05322265625\n",
      "iter: 173 fast_loss: 2850.74609375 slow_loss: 3033.3251953125\n",
      "iter: 173 loss: 6920.8486328125\n",
      "iter: 174 fast_loss: 2734.9091796875 slow_loss: 3105.07958984375\n",
      "iter: 174 loss: 6870.9404296875\n",
      "iter: 175 fast_loss: 2620.513916015625 slow_loss: 3182.18994140625\n",
      "iter: 175 loss: 6831.12939453125\n",
      "iter: 176 fast_loss: 2942.619384765625 slow_loss: 2935.615478515625\n",
      "iter: 176 loss: 6910.181640625\n",
      "iter: 177 fast_loss: 3392.166015625 slow_loss: 2466.77392578125\n",
      "iter: 177 loss: 6891.36279296875\n",
      "iter: 178 fast_loss: 2018.119873046875 slow_loss: 3861.213623046875\n",
      "iter: 178 loss: 6907.25390625\n",
      "iter: 179 fast_loss: 3191.322265625 slow_loss: 2698.10498046875\n",
      "iter: 179 loss: 6912.81494140625\n",
      "iter: 180 fast_loss: 3014.6484375 slow_loss: 2857.337890625\n",
      "iter: 180 loss: 6891.08740234375\n",
      "iter: 181 fast_loss: 2828.9794921875 slow_loss: 3009.49853515625\n",
      "iter: 181 loss: 6855.7099609375\n",
      "iter: 182 fast_loss: 2743.97265625 slow_loss: 3117.919921875\n",
      "iter: 182 loss: 6875.8447265625\n",
      "iter: 183 fast_loss: 3007.781982421875 slow_loss: 2819.84716796875\n",
      "iter: 183 loss: 6843.86328125\n",
      "iter: 184 fast_loss: 3381.04248046875 slow_loss: 2486.06884765625\n",
      "iter: 184 loss: 6878.29638671875\n",
      "iter: 185 fast_loss: 2473.36572265625 slow_loss: 3357.902587890625\n",
      "iter: 185 loss: 6840.6474609375\n",
      "iter: 186 fast_loss: 2745.4833984375 slow_loss: 3100.20458984375\n",
      "iter: 186 loss: 6851.716796875\n",
      "iter: 187 fast_loss: 2927.99365234375 slow_loss: 2973.65576171875\n",
      "iter: 187 loss: 6908.53466796875\n",
      "iter: 188 fast_loss: 2600.532470703125 slow_loss: 3164.2685546875\n",
      "iter: 188 loss: 6771.16357421875\n",
      "iter: 189 fast_loss: 3083.51904296875 slow_loss: 2768.073974609375\n",
      "iter: 189 loss: 6854.2197265625\n",
      "iter: 190 fast_loss: 2732.368408203125 slow_loss: 3112.358154296875\n",
      "iter: 190 loss: 6851.919921875\n",
      "iter: 191 fast_loss: 3204.643310546875 slow_loss: 2637.542724609375\n",
      "iter: 191 loss: 6847.7001953125\n",
      "iter: 192 fast_loss: 2929.3671875 slow_loss: 2949.623046875\n",
      "iter: 192 loss: 6889.1474609375\n",
      "iter: 193 fast_loss: 2801.37646484375 slow_loss: 2970.977783203125\n",
      "iter: 193 loss: 6780.451171875\n",
      "iter: 194 fast_loss: 3009.70458984375 slow_loss: 2819.915771484375\n",
      "iter: 194 loss: 6833.0458984375\n",
      "iter: 195 fast_loss: 2634.86474609375 slow_loss: 3181.29736328125\n",
      "iter: 195 loss: 6814.51953125\n",
      "iter: 196 fast_loss: 2784.27880859375 slow_loss: 2998.786865234375\n",
      "iter: 196 loss: 6776.810546875\n",
      "iter: 197 fast_loss: 2887.824951171875 slow_loss: 2911.376953125\n",
      "iter: 197 loss: 6790.2236328125\n",
      "iter: 198 fast_loss: 3276.53515625 slow_loss: 2564.8955078125\n",
      "iter: 198 loss: 6826.3349609375\n",
      "iter: 199 fast_loss: 3005.10400390625 slow_loss: 2851.020751953125\n",
      "iter: 199 loss: 6838.90283203125\n",
      "iter: 200 fast_loss: 2699.89013671875 slow_loss: 3116.615234375\n",
      "iter: 200 loss: 6798.3974609375\n",
      "usetime: 229.66488242149353\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(200, 200, pic, source, target, path)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")\n",
    "\n",
    "# 198.63224363327026"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x1d24f5b5940>]"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(200)]\n",
    "plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open(file = \"neo_cmp_inner.txt\", mode = \"w\") as file:\n",
    "    for i in loss_li:\n",
    "        file.write(str(i)+\" \")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}