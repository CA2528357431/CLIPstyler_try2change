{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "from network.mynetwork import Unet\n",
    "from loss.loss import CLIPLoss\n",
    "from utils.func import get_features,vgg_normalize\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "lr1 = 0.0004\n",
    "lr2 = 0.0002\n",
    "# lr_fast = 0.0002\n",
    "# lr_slow = 0.00005\n",
    "\n",
    "model = Unet(device).to(device)\n",
    "# model = Unet().to(device)\n",
    "cliploss = CLIPLoss(device)\n",
    "mseloss = torch.nn.MSELoss()\n",
    "# vgg = torchvision.models.vgg19(pretrained=True).features.to(device)\n",
    "# for x in vgg.parameters():\n",
    "#     x.requires_grad = False\n",
    "\n",
    "topil = transforms.ToPILImage()\n",
    "topic = transforms.ToTensor()\n",
    "\n",
    "dir_lambda = 500\n",
    "content_lambda = 150\n",
    "patch_lambda = 9000\n",
    "norm_lambda = 0.002\n",
    "gol_lambda = 300"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "loss_li = []\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def train(iteration1, iteration2, pic, source, target):\n",
    "    input = pic\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic), vgg)\n",
    "    # print(model.parameters())\n",
    "    opt = optim.Adam(model.parameters(), lr=lr1)\n",
    "    for i in range(iteration1):\n",
    "        opt.zero_grad()\n",
    "        neo_pic = model(input)\n",
    "        loss = mseloss(pic, neo_pic) * 1\n",
    "\n",
    "        # loss = 0\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 50) == 0:\n",
    "        #     pil.save(f\"./pic1/{(i + 1) // 50}.jpg\")\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n",
    "\n",
    "\n",
    "    # torch.save(model,'unet.pth')\n",
    "\n",
    "    # model = torch.load('unet.pth')\n",
    "\n",
    "    # pic_f = get_features(vgg_normalize(pic),vgg)\n",
    "\n",
    "    opt = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_fast = optim.Adam(model.parameters(), lr=lr2)\n",
    "    # opt_slow = optim.Adam(model.parameters(), lr=lr_fast)\n",
    "    # opt_loss = optim.Adam(cliploss.parameters(), lr=lr_slow)\n",
    "    for i in range(iteration2):\n",
    "\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # opt_slow.zero_grad()\n",
    "        # opt_fast.zero_grad()\n",
    "\n",
    "        neo_pic = model(input)\n",
    "\n",
    "        dir_loss = 0\n",
    "        dir_loss += cliploss.forward_dir(pic, source, neo_pic, target)\n",
    "\n",
    "        gol_loss = 0\n",
    "        gol_loss += cliploss.forward_gol(pic, source, neo_pic, target)\n",
    "\n",
    "        content_loss = 0\n",
    "        # content_loss += mseloss(pic, neo_pic)\n",
    "        # neo_pic_f = get_features(vgg_normalize(neo_pic), vgg)\n",
    "        # content_loss += torch.mean((pic_f['conv4_2'] - neo_pic_f['conv4_2']) ** 2)\n",
    "        # content_loss += torch.mean((pic_f['conv5_2'] - neo_pic_f['conv5_2']) ** 2)\n",
    "\n",
    "        patch_loss = 0\n",
    "        patch_loss += cliploss.forward_patch(pic, source, neo_pic, target)\n",
    "\n",
    "        norm_loss = 0\n",
    "        norm_loss += cliploss.get_image_prior_losses(neo_pic)\n",
    "\n",
    "        loss = dir_loss * dir_lambda + \\\n",
    "               content_loss * content_lambda + \\\n",
    "               patch_loss * patch_lambda + \\\n",
    "               norm_loss * norm_lambda + \\\n",
    "               gol_loss * gol_lambda\n",
    "\n",
    "\n",
    "\n",
    "        # patch_loss_fast,patch_loss_slow = cliploss.forward_patch_sec(pic, source, neo_pic, target)\n",
    "        # patch_loss_fast.backward(retain_graph=True)\n",
    "        # patch_loss_slow.backward(retain_graph=True)\n",
    "\n",
    "\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        # opt_fast.step()\n",
    "        # opt_slow.step()\n",
    "\n",
    "        loss_li.append(loss.item())\n",
    "\n",
    "        print(\"iter:\", i + 1, \"loss:\", loss.item())\n",
    "\n",
    "\n",
    "        # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "        # if ((i + 1) % 10) == 0:\n",
    "        #     pil.save(f\"./pic2/{(i + 1) // 10}.jpg\")\n",
    "\n",
    "    # return  model(input)\n",
    "    # neo_pic = model(input)\n",
    "    # pil = topil(neo_pic.squeeze(0).cpu())\n",
    "    # # pil.save(f\"{source}-{target}.jpg\")\n",
    "    # pil.save(path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "pil = Image.open(f\"source_pic/modern.jpeg\")\n",
    "ori_size = pil.size[::-1]\n",
    "pil = transforms.Resize(size=(512, 512), interpolation=Image.BICUBIC)(pil)\n",
    "pic = topic(pil).unsqueeze(0).to(device)\n",
    "# pic = torch.ones(1, 3, 512, 512).to(device)\n",
    "pic.requires_grad = False\n",
    "\n",
    "source = \"photo\"\n",
    "# target = \"Van Gogh\"\n",
    "target = \"the scream by Edvard Munch\"\n",
    "path = \"result1.jpg\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter: 1 loss: 0.10949238389730453\n",
      "iter: 2 loss: 0.06761310994625092\n",
      "iter: 3 loss: 0.04318910464644432\n",
      "iter: 4 loss: 0.03041226789355278\n",
      "iter: 5 loss: 0.02267247438430786\n",
      "iter: 6 loss: 0.01786794699728489\n",
      "iter: 7 loss: 0.014840401709079742\n",
      "iter: 8 loss: 0.012469351291656494\n",
      "iter: 9 loss: 0.01080719381570816\n",
      "iter: 10 loss: 0.009587477892637253\n",
      "iter: 11 loss: 0.00882085133343935\n",
      "iter: 12 loss: 0.008265575394034386\n",
      "iter: 13 loss: 0.00780661404132843\n",
      "iter: 14 loss: 0.0073562003672122955\n",
      "iter: 15 loss: 0.006999477744102478\n",
      "iter: 16 loss: 0.006651297211647034\n",
      "iter: 17 loss: 0.00632376316934824\n",
      "iter: 18 loss: 0.0060176001861691475\n",
      "iter: 19 loss: 0.005716527812182903\n",
      "iter: 20 loss: 0.005440790206193924\n",
      "iter: 21 loss: 0.005199176259338856\n",
      "iter: 22 loss: 0.0049752406775951385\n",
      "iter: 23 loss: 0.004719569347798824\n",
      "iter: 24 loss: 0.004506191238760948\n",
      "iter: 25 loss: 0.004295227117836475\n",
      "iter: 26 loss: 0.00407206267118454\n",
      "iter: 27 loss: 0.0038820698391646147\n",
      "iter: 28 loss: 0.00370751041918993\n",
      "iter: 29 loss: 0.0035463273525238037\n",
      "iter: 30 loss: 0.0034139123745262623\n",
      "iter: 31 loss: 0.0032772677950561047\n",
      "iter: 32 loss: 0.0031665563583374023\n",
      "iter: 33 loss: 0.0030734501779079437\n",
      "iter: 34 loss: 0.0029903508257120848\n",
      "iter: 35 loss: 0.0029162417631596327\n",
      "iter: 36 loss: 0.0028457248117774725\n",
      "iter: 37 loss: 0.0027786754071712494\n",
      "iter: 38 loss: 0.002703487640246749\n",
      "iter: 39 loss: 0.0026435446925461292\n",
      "iter: 40 loss: 0.002583641093224287\n",
      "iter: 41 loss: 0.0025270581245422363\n",
      "iter: 42 loss: 0.002478941809386015\n",
      "iter: 43 loss: 0.0024278070777654648\n",
      "iter: 44 loss: 0.002378926146775484\n",
      "iter: 45 loss: 0.0023372741416096687\n",
      "iter: 46 loss: 0.0022930512204766273\n",
      "iter: 47 loss: 0.0022504697553813457\n",
      "iter: 48 loss: 0.0022113523446023464\n",
      "iter: 49 loss: 0.002166958525776863\n",
      "iter: 50 loss: 0.002127002691850066\n",
      "iter: 51 loss: 0.0020901146344840527\n",
      "iter: 52 loss: 0.0020574512891471386\n",
      "iter: 53 loss: 0.002026112750172615\n",
      "iter: 54 loss: 0.001991401892155409\n",
      "iter: 55 loss: 0.001960579538717866\n",
      "iter: 56 loss: 0.0019351248629391193\n",
      "iter: 57 loss: 0.001900629373267293\n",
      "iter: 58 loss: 0.00187694001942873\n",
      "iter: 59 loss: 0.001851282431744039\n",
      "iter: 60 loss: 0.0018263452220708132\n",
      "iter: 61 loss: 0.0017983035650104284\n",
      "iter: 62 loss: 0.0017788929399102926\n",
      "iter: 63 loss: 0.0017519815592095256\n",
      "iter: 64 loss: 0.0017301210900768638\n",
      "iter: 65 loss: 0.0017101527191698551\n",
      "iter: 66 loss: 0.0016854037530720234\n",
      "iter: 67 loss: 0.0016677597304806113\n",
      "iter: 68 loss: 0.001649928279221058\n",
      "iter: 69 loss: 0.0016291372012346983\n",
      "iter: 70 loss: 0.001611420651897788\n",
      "iter: 71 loss: 0.0015915681142359972\n",
      "iter: 72 loss: 0.0015735746128484607\n",
      "iter: 73 loss: 0.0015533098485320807\n",
      "iter: 74 loss: 0.001534799113869667\n",
      "iter: 75 loss: 0.0015202395152300596\n",
      "iter: 76 loss: 0.0015018901322036982\n",
      "iter: 77 loss: 0.001487887930124998\n",
      "iter: 78 loss: 0.0014751491835340858\n",
      "iter: 79 loss: 0.0014586066827178001\n",
      "iter: 80 loss: 0.0014438747894018888\n",
      "iter: 81 loss: 0.0014281196054071188\n",
      "iter: 82 loss: 0.0014155127573758364\n",
      "iter: 83 loss: 0.0014011671300977468\n",
      "iter: 84 loss: 0.0013862343039363623\n",
      "iter: 85 loss: 0.0013718785485252738\n",
      "iter: 86 loss: 0.0013592438772320747\n",
      "iter: 87 loss: 0.0013459648471325636\n",
      "iter: 88 loss: 0.0013357284478843212\n",
      "iter: 89 loss: 0.0013218072708696127\n",
      "iter: 90 loss: 0.0013085826067253947\n",
      "iter: 91 loss: 0.0012991167604923248\n",
      "iter: 92 loss: 0.0012868919875472784\n",
      "iter: 93 loss: 0.0012744199484586716\n",
      "iter: 94 loss: 0.0012643723748624325\n",
      "iter: 95 loss: 0.0012540146708488464\n",
      "iter: 96 loss: 0.0012420635903254151\n",
      "iter: 97 loss: 0.0012314696796238422\n",
      "iter: 98 loss: 0.001221118844114244\n",
      "iter: 99 loss: 0.001208569621667266\n",
      "iter: 100 loss: 0.0011999554699286819\n",
      "iter: 1 loss: 9708.0859375\n",
      "iter: 2 loss: 9580.076171875\n",
      "iter: 3 loss: 9460.0498046875\n",
      "iter: 4 loss: 9428.03515625\n",
      "iter: 5 loss: 9292.02734375\n",
      "iter: 6 loss: 9348.0224609375\n",
      "iter: 7 loss: 9204.0224609375\n",
      "iter: 8 loss: 9140.021484375\n",
      "iter: 9 loss: 9100.01953125\n",
      "iter: 10 loss: 9068.0185546875\n",
      "iter: 11 loss: 9084.0166015625\n",
      "iter: 12 loss: 8996.0126953125\n",
      "iter: 13 loss: 9068.0087890625\n",
      "iter: 14 loss: 9068.005859375\n",
      "iter: 15 loss: 8900.005859375\n",
      "iter: 16 loss: 8980.005859375\n",
      "iter: 17 loss: 8908.0078125\n",
      "iter: 18 loss: 8916.0087890625\n",
      "iter: 19 loss: 8828.0146484375\n",
      "iter: 20 loss: 8796.0224609375\n",
      "iter: 21 loss: 8884.0302734375\n",
      "iter: 22 loss: 8804.037109375\n",
      "iter: 23 loss: 8844.0419921875\n",
      "iter: 24 loss: 8764.04296875\n",
      "iter: 25 loss: 8716.0419921875\n",
      "iter: 26 loss: 8724.041015625\n",
      "iter: 27 loss: 8692.0390625\n",
      "iter: 28 loss: 8788.0380859375\n",
      "iter: 29 loss: 8732.0380859375\n",
      "iter: 30 loss: 8724.0419921875\n",
      "iter: 31 loss: 8676.0439453125\n",
      "iter: 32 loss: 8692.048828125\n",
      "iter: 33 loss: 8692.0517578125\n",
      "iter: 34 loss: 8604.0546875\n",
      "iter: 35 loss: 8620.0556640625\n",
      "iter: 36 loss: 8604.0537109375\n",
      "iter: 37 loss: 8660.0537109375\n",
      "iter: 38 loss: 8652.0537109375\n",
      "iter: 39 loss: 8564.0546875\n",
      "iter: 40 loss: 8548.0595703125\n",
      "iter: 41 loss: 8540.0634765625\n",
      "iter: 42 loss: 8548.068359375\n",
      "iter: 43 loss: 8548.072265625\n",
      "iter: 44 loss: 8500.0751953125\n",
      "iter: 45 loss: 8448.076171875\n",
      "iter: 46 loss: 8508.072265625\n",
      "iter: 47 loss: 8452.06640625\n",
      "iter: 48 loss: 8472.0625\n",
      "iter: 49 loss: 8432.0625\n",
      "iter: 50 loss: 8448.060546875\n",
      "iter: 51 loss: 8472.068359375\n",
      "iter: 52 loss: 8427.8251953125\n",
      "iter: 53 loss: 8444.0771484375\n",
      "iter: 54 loss: 8372.0791015625\n",
      "iter: 55 loss: 8340.078125\n",
      "iter: 56 loss: 8440.076171875\n",
      "iter: 57 loss: 8364.068359375\n",
      "iter: 58 loss: 8312.0673828125\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [6], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m start \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m----> 2\u001B[0m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m end \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m      4\u001B[0m usetime \u001B[38;5;241m=\u001B[39m end \u001B[38;5;241m-\u001B[39m start\n",
      "Cell \u001B[1;32mIn [4], line 51\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(iteration1, iteration2, pic, source, target)\u001B[0m\n\u001B[0;32m     48\u001B[0m neo_pic \u001B[38;5;241m=\u001B[39m model(\u001B[38;5;28minput\u001B[39m)\n\u001B[0;32m     50\u001B[0m dir_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m---> 51\u001B[0m dir_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[43mcliploss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_dir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mneo_pic\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     53\u001B[0m gol_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     54\u001B[0m gol_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m cliploss\u001B[38;5;241m.\u001B[39mforward_gol(pic, source, neo_pic, target)\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:311\u001B[0m, in \u001B[0;36mCLIPLoss.forward_dir\u001B[1;34m(self, src_img, source_class, target_img, target_class)\u001B[0m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_dir\u001B[39m(\u001B[38;5;28mself\u001B[39m, src_img: torch\u001B[38;5;241m.\u001B[39mTensor, source_class: \u001B[38;5;28mstr\u001B[39m, target_img: torch\u001B[38;5;241m.\u001B[39mTensor, target_class: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m--> 311\u001B[0m     dir_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;241m*\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclip_directional_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_img\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msource_class\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_img\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_class\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    312\u001B[0m     \u001B[38;5;66;03m# dir_loss += 1 * self.patch_directional_loss(src_img, source_class, target_img, target_class)\u001B[39;00m\n\u001B[0;32m    313\u001B[0m     \u001B[38;5;66;03m# dir_loss = 1 * self.global_clip_loss(target_img, f\"a {target_class}\")\u001B[39;00m\n\u001B[0;32m    314\u001B[0m     \u001B[38;5;66;03m# dir_loss += 1 * self.clip_angle_loss(src_img, source_class, target_img, target_class)\u001B[39;00m\n\u001B[0;32m    315\u001B[0m     \u001B[38;5;66;03m# print(loss1.item(),loss2.item(),loss3.item(),loss4.item())\u001B[39;00m\n\u001B[0;32m    316\u001B[0m     \u001B[38;5;66;03m# loss += loss1 + loss2 + loss3 + loss4\u001B[39;00m\n\u001B[0;32m    317\u001B[0m     \u001B[38;5;66;03m# loss.requires_grad = True\u001B[39;00m\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m dir_loss\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:195\u001B[0m, in \u001B[0;36mCLIPLoss.clip_directional_loss\u001B[1;34m(self, src_img, source_class, target_img, target_class)\u001B[0m\n\u001B[0;32m    192\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_direction \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    193\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_direction \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcompute_text_direction(source_class, target_class)\u001B[38;5;241m.\u001B[39mdetach()\n\u001B[1;32m--> 195\u001B[0m src_encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_image_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43msrc_img\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    196\u001B[0m target_encoding \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mget_image_features(target_img)\n\u001B[0;32m    198\u001B[0m edit_direction \u001B[38;5;241m=\u001B[39m (target_encoding \u001B[38;5;241m-\u001B[39m src_encoding)\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:173\u001B[0m, in \u001B[0;36mCLIPLoss.get_image_features\u001B[1;34m(self, img, norm)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_image_features\u001B[39m(\u001B[38;5;28mself\u001B[39m, img: torch\u001B[38;5;241m.\u001B[39mTensor, norm: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[1;32m--> 173\u001B[0m     image_features \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_images\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    175\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m norm:\n\u001B[0;32m    176\u001B[0m         image_features \u001B[38;5;241m/\u001B[39m\u001B[38;5;241m=\u001B[39m image_features\u001B[38;5;241m.\u001B[39mclone()\u001B[38;5;241m.\u001B[39mnorm(dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, keepdim\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:151\u001B[0m, in \u001B[0;36mCLIPLoss.encode_images\u001B[1;34m(self, images)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode_images\u001B[39m(\u001B[38;5;28mself\u001B[39m, images: torch\u001B[38;5;241m.\u001B[39mTensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m torch\u001B[38;5;241m.\u001B[39mTensor:\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;66;03m# images = torch.nn.functional.interpolate(images, (224,224), mode=\"bilinear\")\u001B[39;00m\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;66;03m# images = self.preprocess(images.squeeze(0).cpu())\u001B[39;00m\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;66;03m# images = images.to(self.device).unsqueeze(0)\u001B[39;00m\n\u001B[1;32m--> 151\u001B[0m     images \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpreprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    152\u001B[0m     code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mencode_image(images)\n\u001B[0;32m    153\u001B[0m     code \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc(code)\n",
      "File \u001B[1;32mE:\\Anaconda\\envs\\sth\\lib\\site-packages\\torch\\nn\\modules\\module.py:727\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m    725\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_slow_forward(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    726\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 727\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    728\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m itertools\u001B[38;5;241m.\u001B[39mchain(\n\u001B[0;32m    729\u001B[0m         _global_forward_hooks\u001B[38;5;241m.\u001B[39mvalues(),\n\u001B[0;32m    730\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks\u001B[38;5;241m.\u001B[39mvalues()):\n\u001B[0;32m    731\u001B[0m     hook_result \u001B[38;5;241m=\u001B[39m hook(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m, result)\n",
      "File \u001B[1;32mE:\\nada_clean\\loss\\loss.py:76\u001B[0m, in \u001B[0;36mPreprocess.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m     74\u001B[0m mean \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m0.48145466\u001B[39m, \u001B[38;5;241m0.4578275\u001B[39m, \u001B[38;5;241m0.40821073\u001B[39m])\n\u001B[0;32m     75\u001B[0m mean \u001B[38;5;241m=\u001B[39m mean\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m---> 76\u001B[0m mean \u001B[38;5;241m=\u001B[39m \u001B[43mmean\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexpand\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshape\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     77\u001B[0m std \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mtensor([\u001B[38;5;241m0.26862954\u001B[39m, \u001B[38;5;241m0.26130258\u001B[39m, \u001B[38;5;241m0.27577711\u001B[39m])\n\u001B[0;32m     78\u001B[0m std \u001B[38;5;241m=\u001B[39m std\u001B[38;5;241m.\u001B[39mreshape(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "train(100, 100, pic, source, target)\n",
    "end = time.time()\n",
    "usetime = end - start\n",
    "print(f\"usetime: {usetime}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "neo_pic = model(pic)\n",
    "pil = topil(neo_pic.squeeze(0).cpu())\n",
    "pil = transforms.Resize(size=ori_size, interpolation=Image.BICUBIC)(pil)\n",
    "pil.save(path)\n",
    "\n",
    "\n",
    "\n",
    "# 186.4968602657318\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(file = \"neo.txt\", mode = \"w\") as file:\n",
    "    for i in loss_li:\n",
    "        file.write(str(i)+\" \")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = [i for i in range(100)]\n",
    "plt.plot(x,loss_li,color=\"red\",marker=\"o\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x = [[i,i+1] for i in range(100)]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}